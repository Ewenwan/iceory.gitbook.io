
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Ternary Weight Networks Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.2">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-etoc/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="Trained Ternary Quantization.html" />
    
    
    <link rel="prev" href="Binary Weight Networks.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="Introduction.html">
            
                <a href="Introduction.html">
            
                    
                    Network Quantization
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="Incremental Network Quantization.html">
            
                <a href="Incremental Network Quantization.html">
            
                    
                    Incremental Network Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="Dynamic Network Surgery.html">
            
                <a href="Dynamic Network Surgery.html">
            
                    
                    Dynamic Network Surgery
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="Binary Weight Networks.html">
            
                <a href="Binary Weight Networks.html">
            
                    
                    Binary Weight Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.4" data-path="Ternary Weight Networks.html">
            
                <a href="Ternary Weight Networks.html">
            
                    
                    Ternary Weight Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="Trained Ternary Quantization.html">
            
                <a href="Trained Ternary Quantization.html">
            
                    
                    Trained Ternary Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="Binarized Neural Networks.html">
            
                <a href="Binarized Neural Networks.html">
            
                    
                    Binarized Neural Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="Deep Compression.html">
            
                <a href="Deep Compression.html">
            
                    
                    Deep Compression
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Notes
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../notes/gitbook.html">
            
                <a href="../notes/gitbook.html">
            
                    
                    Install and Use Gitbook on Windows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../notes/softmaxloss.html">
            
                <a href="../notes/softmaxloss.html">
            
                    
                    Softmax Loss with Symbolic Differentiation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../notes/pytorch_autograd.html">
            
                <a href="../notes/pytorch_autograd.html">
            
                    
                    PyTorch and Automatic Differentiation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../notes/caffe2.html">
            
                <a href="../notes/caffe2.html">
            
                    
                    Install Caffe2 on Windows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../notes/markdown.html">
            
                <a href="../notes/markdown.html">
            
                    
                    Markdown Tutorial
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../notes/vscode.html">
            
                <a href="../notes/vscode.html">
            
                    
                    VSCode
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../notes/auxnet.html">
            
                <a href="../notes/auxnet.html">
            
                    
                    Re-implementation of AuxNet
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="../notes/git.html">
            
                <a href="../notes/git.html">
            
                    
                    Git
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="../notes/git.html">
            
                <a href="../notes/git.html">
            
                    
                    Power Point
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Ternary Weight Networks</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="twn-ternary-weight-networks">TWN (Ternary Weight Networks)</h1>
<!-- toc --><div id="toc" class="toc">

<ul>
<li><a href="#training-methods">Training Methods</a><ul>
<li><a href="#important-tips">Important Tips</a></li>
</ul>
</li>
<li><a href="#experimental-results">Experimental Results</a></li>
</ul>

</div><!-- tocstop -->
<p>The authors introduced <a href="https://www.researchgate.net/publication/303270485_Ternary_Weight_Networks?ev=auth_pub" target="_blank">ternary weight networks</a> (TWNs) to address the limited storage and computational resources issues in hardware. The quantization problem can be formulated as follows:
<script type="math/tex; mode=display">
\begin{cases}
\alpha^*, W^{t*} = &\arg\min_{\alpha, W^t} J(\alpha, W^t) = \|W-\alpha W^t\|_2^2 \\ 
s.t. & a\ge0, W_i^t\in\{-1,0,1\}, i=1,2,\dots, n. 
\end{cases} \tag{1}
</script>
Here <script type="math/tex; ">n</script> is the size of filter, <script type="math/tex; ">W</script> represents weights of the network. With <script type="math/tex; ">W\approx \alpha W^t</script> and assuming the convolutional layer do not have bias term, forward propagation of ternary weight networks is as follows:
<script type="math/tex; mode=display">
\begin{cases}
Z & = &X*W \approx X*(\alpha W^t) = (\alpha X)\oplus W^t \\
X^{next} & = & g(Z)
\end{cases} \tag{2}
</script>
where <script type="math/tex; ">X</script> indicates inputs, <script type="math/tex; ">*</script> indicates convolutional operation, <script type="math/tex; ">g</script> is the non-linear activation function, <script type="math/tex; ">\oplus</script> indicates the inner product or convolutional operation without any multiplication, <script type="math/tex; ">X^{next}</script> indicates the outputs.</p>
<p>The approximated solution of <script type="math/tex; ">W</script> with threshold-based ternary function is as follows:
<script type="math/tex; mode=display">
W_i^t = f_t(W_i|\triangle) = 
\begin{cases}
+1, if~W_i \gt \triangle \\
0, if~|W_i| \le \triangle \\
-1, if~W_i \lt -\triangle 
\end{cases} \tag{3}
</script>
The optimized objective function can be written as:
<script type="math/tex; mode=display">
\alpha^*, \triangle^* = \arg\min_{\alpha\ge0, \triangle\gt 0}(|I_\triangle|\alpha^2-2(\sum_{i\in I_\triangle}|W_i|)\alpha+c_\triangle) \tag{4}
</script>
where <script type="math/tex; ">I_\triangle = \{i|~|W|\gt\triangle\}</script> and <script type="math/tex; ">|I_\triangle|</script> denotes the number of elements in <script type="math/tex; ">I_\triangle</script>; <script type="math/tex; ">c_\triangle = \sum_{i\in I_\triangle^c}W_i^2</script> is a <script type="math/tex; ">\alpha</script>-independent constant. Thus the optimal solutions of the objective function can be computed as follows: 
<script type="math/tex; mode=display">
\alpha_\triangle^* = \frac{1}{|I_\triangle|}\sum_{i\in I_\triangle}|W_i| \\
\triangle^* = \arg\max_{\triangle\gt 0}(\sum_{i\in I_\triangle}|W_i|^2) \tag{5}
</script>
Here solution of <script type="math/tex; ">\triangle</script> is approximated by <script type="math/tex; ">\triangle^*\approx0.7\cdot E(|W|) \approx \frac{0.7}{n}\sum_{i=1}^n|W_i|</script>.</p>
<h2 id="training-methods">Training Methods</h2>
<p>The training of ternary weight networks can be summarized to three steps: quantization, training and updating. Quantization phase is to quantize the weights of convolutional layers using Equation (5), then apply standard forward and backward propagation to the network, and update parameters using standard SGD. <a href="https://github.com/fengfu-chris/caffe-twns" target="_blank">Source code</a> is available on GitHub.</p>
<h3 id="important-tips">Important Tips</h3>
<ul>
<li><script type="math/tex; ">\alpha</script> is used as the scaling factor for input <script type="math/tex; ">X</script> not for weights <script type="math/tex; ">W</script></li>
<li>gradient is computed using <script type="math/tex; ">W^t</script> </li>
<li>quantized weights are used during forward and backward but not during parameters update, so <script type="math/tex; ">W_l^r \gets W_l^r - \eta \frac{\partial C}{\partial W_l^t} </script></li>
<li>first compute <script type="math/tex; ">\triangle</script> then compute mask, finally compute <script type="math/tex; ">\alpha</script> </li>
<li><script type="math/tex; ">\triangle</script> is computed with all <script type="math/tex; ">|W^r|</script> while <script type="math/tex; ">\alpha</script> is computed only with those <script type="math/tex; ">|W^r|>\triangle</script></li>
<li>apply weight_decay would lead results worse </li>
<li><a href="http://blog.csdn.net/xjtu_noc_wei/article/details/52862282" target="_blank">this blog</a> is useful for implementation</li>
</ul>
<h2 id="experimental-results">Experimental Results</h2>
<p>Three data sets are used in this paper, including MNIST, CIFAR-10, ImageNet. To different data sets, the authors conducted experiments using LeNet-5 (32-C5 + MP2 + 64-C5 + MP2 + 512FC + SVM), VGG-inspired network (2<script type="math/tex; ">\times</script>(128-C3) + MP2 + 2<script type="math/tex; ">\times</script>(256-C3) + MP2 + 2<script type="math/tex; ">\times</script>(512-C3) + MP2 + 1024-FC + Softmax), ResNet-18, respectively. Network architecture and parameters setting for different data sets are shown as follows:</p>
<table>
<thead>
<tr>
<th></th>
<th>MNIST</th>
<th>CIFAR-10</th>
<th>ImageNet</th>
</tr>
</thead>
<tbody>
<tr>
<td>network architecture</td>
<td>LeNet-5</td>
<td>VGG-7</td>
<td>ResNet-18 (B)</td>
</tr>
<tr>
<td>weight decay</td>
<td>1e-4</td>
<td>1e-4</td>
<td>1e-4</td>
</tr>
<tr>
<td>mini-batch size of BN</td>
<td>50</td>
<td>100</td>
<td>64(<script type="math/tex; ">\times</script>4 GPUs)</td>
</tr>
<tr>
<td>initial learning rate</td>
<td>0.01</td>
<td>0.1</td>
<td>0.1</td>
</tr>
<tr>
<td>learning rate decay (divided by 10) epochs</td>
<td>15, 25</td>
<td>80, 120</td>
<td>30, 40, 50</td>
</tr>
<tr>
<td>momentum</td>
<td>0.9</td>
<td>0.9</td>
<td>0.9</td>
</tr>
</tbody>
</table>
<p>Comparison of the proposed method and the previous methods are shown as follows:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Method</th>
<th style="text-align:center">MINIST</th>
<th style="text-align:center">CIFAR-10</th>
<th style="text-align:center">ImageNet Top1 (ResNet-18 / ResNet-18B)</th>
<th style="text-align:center">ImageNet Top5 (ResNet-18 / ResNet-18B)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">TWN</td>
<td style="text-align:center">99.35</td>
<td style="text-align:center">92.56</td>
<td style="text-align:center">61.8 / 65.3</td>
<td style="text-align:center">84.2 / 86.2</td>
</tr>
<tr>
<td style="text-align:center">BPWN</td>
<td style="text-align:center">99.05</td>
<td style="text-align:center">90.18</td>
<td style="text-align:center">57.5 / 61.6</td>
<td style="text-align:center">81.2 / 83.9</td>
</tr>
<tr>
<td style="text-align:center">FPWN (full precision)</td>
<td style="text-align:center">99.41</td>
<td style="text-align:center">92.88</td>
<td style="text-align:center">65.4 / 67.6</td>
<td style="text-align:center">86.76 / 88.0</td>
</tr>
<tr>
<td style="text-align:center">Binary Connect</td>
<td style="text-align:center">98.82</td>
<td style="text-align:center">91.73</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">Binarized Neural Networks</td>
<td style="text-align:center">88.6</td>
<td style="text-align:center">89.85</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">Binary Weight Networks</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">60.8</td>
<td style="text-align:center">83.0</td>
</tr>
<tr>
<td style="text-align:center">XNOR-Net</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">51.2</td>
<td style="text-align:center">73.2</td>
</tr>
</tbody>
</table>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="Binary Weight Networks.html" class="navigation navigation-prev " aria-label="Previous page: Binary Weight Networks">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="Trained Ternary Quantization.html" class="navigation navigation-next " aria-label="Next page: Trained Ternary Quantization">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Ternary Weight Networks","level":"1.2.4","depth":2,"next":{"title":"Trained Ternary Quantization","level":"1.2.5","depth":2,"path":"Network Quantization/Trained Ternary Quantization.md","ref":"Network Quantization/Trained Ternary Quantization.md","articles":[]},"previous":{"title":"Binary Weight Networks","level":"1.2.3","depth":2,"path":"Network Quantization/Binary Weight Networks.md","ref":"Network Quantization/Binary Weight Networks.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","splitter","back-to-top-button","etoc","-search","-lunr","search-pro"],"pluginsConfig":{"etoc":{"h2lb":3,"header":1,"maxdepth":4,"mindepth":3,"notoc":false},"splitter":{},"search-pro":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"Network Quantization/Ternary Weight Networks.md","mtime":"2017-06-24T16:29:33.738Z","type":"markdown"},"gitbook":{"version":"3.2.2","time":"2017-11-28T07:10:47.366Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-etoc/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

