
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Integer Arithmetic Only Inference Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.2">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-etoc/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    
    <link rel="prev" href="Deep Compression.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="Introduction.html">
            
                <a href="Introduction.html">
            
                    
                    Network Quantization
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="Incremental Network Quantization.html">
            
                <a href="Incremental Network Quantization.html">
            
                    
                    Incremental Network Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="Dynamic Network Surgery.html">
            
                <a href="Dynamic Network Surgery.html">
            
                    
                    Dynamic Network Surgery
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="Binary Weight Networks.html">
            
                <a href="Binary Weight Networks.html">
            
                    
                    Binary Weight Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="Ternary Weight Networks.html">
            
                <a href="Ternary Weight Networks.html">
            
                    
                    Ternary Weight Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="Trained Ternary Quantization.html">
            
                <a href="Trained Ternary Quantization.html">
            
                    
                    Trained Ternary Quantization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="Binarized Neural Networks.html">
            
                <a href="Binarized Neural Networks.html">
            
                    
                    Binarized Neural Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="Deep Compression.html">
            
                <a href="Deep Compression.html">
            
                    
                    Deep Compression
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.8" data-path="Integer Arithmetic Only Inference.html">
            
                <a href="Integer Arithmetic Only Inference.html">
            
                    
                    Integer Arithmetic Only Inference
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Notes
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../notes/gitbook.html">
            
                <a href="../notes/gitbook.html">
            
                    
                    Install and Use Gitbook on Windows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../notes/manual_vs_auto_gradient.html">
            
                <a href="../notes/manual_vs_auto_gradient.html">
            
                    
                    Softmax Loss with Different Differentiation Methods
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../notes/pytorch_autograd.html">
            
                <a href="../notes/pytorch_autograd.html">
            
                    
                    PyTorch and Automatic Differentiation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../notes/caffe2.html">
            
                <a href="../notes/caffe2.html">
            
                    
                    Install Caffe2 on Windows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../notes/markdown.html">
            
                <a href="../notes/markdown.html">
            
                    
                    Markdown Tutorial
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../notes/vscode.html">
            
                <a href="../notes/vscode.html">
            
                    
                    VSCode
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../notes/auxnet.html">
            
                <a href="../notes/auxnet.html">
            
                    
                    Re-implementation of AuxNet
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="../notes/git.html">
            
                <a href="../notes/git.html">
            
                    
                    Git
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="../notes/git.html">
            
                <a href="../notes/git.html">
            
                    
                    Power Point
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.10" data-path="../notes/pyplot.html">
            
                <a href="../notes/pyplot.html">
            
                    
                    PyPlot
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Integer Arithmetic Only Inference</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="quantization-and-training-of-neural-networks-for-efficient-integer-arithmetic-only-inference">Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</h1>
<!-- toc --><div id="toc" class="toc">

<ul>
<li><a href="#training-with-simulated-quantization">Training with simulated quantization</a><ul>
<li><a href="#point-wise-quantization">Point-wise quantization:</a></li>
<li><a href="#compute-gradient">compute gradient</a></li>
</ul>
</li>
<li><a href="#inference-with-integer-arithmetic-only">Inference with integer-arithmetic only</a><ul>
<li><a href="#data-type">Data type</a></li>
<li><a href="#affine-mapping-from-q-to-r">Affine mapping from q to r</a></li>
<li><a href="#the-following-operations">The Following operations</a></li>
<li><a href="#batch-normalization-folding">Batch normalization folding</a></li>
<li><a href="#graph-illustration">Graph illustration</a><ul>
<li><a href="#simple-graph-for-single-layer">simple graph for single layer</a></li>
<li><a href="#layer-with-bypass">layer with bypass</a></li>
<li><a href="#convolutional-layer-with-batch-normalization">convolutional layer with batch normalization</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div><!-- tocstop -->
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1712.05877" target="_blank">https://arxiv.org/abs/1712.05877</a></p>
<p><strong>Code</strong>: refer to TensorFlowLite.quantize</p>
<h2 id="training-with-simulated-quantization">Training with simulated quantization</h2>
<h3 id="point-wise-quantization">Point-wise quantization:</h3>
<p><script type="math/tex; ">clamp(r;a,b) := min(max(r, a), b)</script></p>
<p><script type="math/tex; ">s(a,b,n) := \frac{b-a}{n-1}</script></p>
<p><script type="math/tex; ">q(r;a,b,n):=\lfloor \frac{clamp(r;a,b)-a}{s(a,b,n)} \rceil s(a,b,n)+a</script></p>
<p>Here, $r$ represents the real value, $q$ represents the quantized value. $\lfloor \cdot \rceil$ denotes rounding to the nearest integer.</p>
<ul>
<li><p>for weights: $a:=min(w), b:=max(w)$</p>
</li>
<li><p>for activation: collect [a;b] during training and aggregate them via exponential moving average (EMA)</p>
</li>
</ul>
<pre><code>exponential moving average (EMA) in tensorflow:

shallow_variable -= (1-decay) * (shallow_variable-variable)

reasonable values for decay are close to 1.0, e.g., 0.999, 0.99999, etc
</code></pre><p><strong>Note: activation quantization is disabled at the start of training</strong> </p>
<h3 id="compute-gradient">compute gradient</h3>
<p><script type="math/tex; "> \frac{\partial{L}}{\partial{r}} = \frac{\partial{L}}{\partial{q}}\frac{\partial{q}}{\partial{r}}</script></p>
<p>Here, we have $\frac{\partial{q}}{\partial{r}}=0$ if $r\notin[a,b]$, otherwise $\frac{\partial{q}}{\partial{r}}=1$.</p>
<h2 id="inference-with-integer-arithmetic-only">Inference with integer-arithmetic only</h2>
<h3 id="data-type">Data type</h3>
<ul>
<li><p>input: uint8</p>
</li>
<li><p>weights: uint8</p>
</li>
<li><p>bias: int32</p>
</li>
<li><p>activation: int32</p>
</li>
<li><p>output: uint8</p>
</li>
</ul>
<h3 id="affine-mapping-from-q-to-r">Affine mapping from q to r</h3>
<p>Formulation:</p>
<p><script type="math/tex; "> r = S(q-Z) \to q=\frac{r}{S}+Z</script></p>
<p>where $S$ means &quot;Scale&quot; and $Z$ means &quot;Zero point&quot;. And $S=s(a,b,n), Z=z(a,b,n)$.</p>
<p>Therefore, considering $r_3=r_1*r_2$:</p>
<p><script type="math/tex; ">r_3 = S_3(q_3-Z_3), r_1*r_2=S_1S_2(q_1-Z_1)(q_2-Z_2)</script></p>
<p><script type="math/tex; ">q_3 = \frac{S_1S_2}{S_3}(q_1-Z_1)(q_2-Z_2)+Z_3</script></p>
<p>Let $M:=\frac{S_1S_2}{S_3}$ and $M=2^{-n}M_0$, $M_0\in(0.5,1]$.</p>
<p>For matrix multiplication of two matrices with size of $N\times N$.</p>
<p><script type="math/tex; ">q_3^{(i,k)} = Z_3 +M\sum_{j=1}^{N}(q_1^{(i,j)}-Z_1)(q_2^{(j,k)}-Z_2)</script></p>
<p>It needs $O(N^3)$ subtraction to compute the result. </p>
<p>More efficient implementation:</p>
<p><script type="math/tex; ">q_3^{(i,k)} = Z_3 + M(\sum_{j=1}^N q_1^{(i,j)}q_2^{(j,k)}-\sum_{j=1}^N q_1^{(i,j)}Z_2-\sum_{j=1}^N q_2^{(j,k)}Z_1 + \sum_{j=1}^N Z_1Z_2)</script></p>
<p><script type="math/tex; ">q_3^{(i,k)} = Z_3 + M(\sum_{j=1}^N q_1^{(i,j)}q_2^{(j,k)}-Z_2 \bar a_1^{(i)}- Z_1a_2^{(k)} + N Z_1Z_2)</script>,</p>
<p>where $\bar a<em>1^{(i)}:=\sum</em>{j=1}^N q<em>1^{(i,j)}$ and $a_2^{(k)}:=\sum</em>{j=1}^N q<em>2^{(j,k)}$. Therefore, the computational costs is mainly from the computation of $\sum</em>{j=1}^N q_1^{(i,j)}q_2^{(j,k)}$</p>
<h3 id="the-following-operations">The Following operations</h3>
<ul>
<li><p>scale down: int32 activation --&gt; int8 output activation</p>
</li>
<li><p>cast down: int8 activation --&gt; uint8 output</p>
</li>
</ul>
<h3 id="batch-normalization-folding">Batch normalization folding</h3>
<p><script type="math/tex; "> w_{fold}:=\frac{\gamma w}{\sqrt{EMA(\sigma_B^2)+\epsilon}}</script></p>
<h3 id="graph-illustration">Graph illustration</h3>
<h4 id="simple-graph-for-single-layer">simple graph for single layer</h4>
<ul>
<li>origin</li>
</ul>
<p><img src="fig/integer_arithmetic_only/simple_origin.png" alt="simple_graph_origin"></p>
<ul>
<li>quantized</li>
</ul>
<p><img src="fig/integer_arithmetic_only/simple_quantize.png" alt="simple_graph_origin"></p>
<h4 id="layer-with-bypass">layer with bypass</h4>
<ul>
<li>origin</li>
</ul>
<p><img src="fig/integer_arithmetic_only/bypass_origin.png" alt="simple_graph_origin"></p>
<ul>
<li>quantized</li>
</ul>
<p><img src="fig/integer_arithmetic_only/bypass_quantize.png" alt="simple_graph_origin"></p>
<h4 id="convolutional-layer-with-batch-normalization">convolutional layer with batch normalization</h4>
<ul>
<li>training</li>
</ul>
<p><img src="fig/integer_arithmetic_only/conv_bn_training.png" alt="simple_graph_origin"></p>
<ul>
<li>inference</li>
</ul>
<p><img src="fig/integer_arithmetic_only/conv_bn_inference.png" alt="simple_graph_origin"></p>
<ul>
<li>training with fold</li>
</ul>
<p><img src="fig/integer_arithmetic_only/conv_bn_training_fold.png" alt="simple_graph_origin"></p>
<ul>
<li>training with fold quantized</li>
</ul>
<p><img src="fig/integer_arithmetic_only/conv_bn_training_fold_quantize.png" alt="simple_graph_origin"></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="Deep Compression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page: Deep Compression">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Integer Arithmetic Only Inference","level":"1.2.8","depth":2,"next":{"title":"Notes","level":"1.3","depth":1,"ref":"","articles":[{"title":"Install and Use Gitbook on Windows","level":"1.3.1","depth":2,"path":"notes/gitbook.md","ref":"notes/gitbook.md","articles":[]},{"title":"Softmax Loss with Different Differentiation Methods","level":"1.3.2","depth":2,"path":"notes/manual_vs_auto_gradient.md","ref":"notes/manual_vs_auto_gradient.md","articles":[]},{"title":"PyTorch and Automatic Differentiation","level":"1.3.3","depth":2,"path":"notes/pytorch_autograd.md","ref":"notes/pytorch_autograd.md","articles":[]},{"title":"Install Caffe2 on Windows","level":"1.3.4","depth":2,"path":"notes/caffe2.md","ref":"notes/caffe2.md","articles":[]},{"title":"Markdown Tutorial","level":"1.3.5","depth":2,"path":"notes/markdown.md","ref":"notes/markdown.md","articles":[]},{"title":"VSCode","level":"1.3.6","depth":2,"path":"notes/vscode.md","ref":"notes/vscode.md","articles":[]},{"title":"Re-implementation of AuxNet","level":"1.3.7","depth":2,"path":"notes/auxnet.md","ref":"notes/auxnet.md","articles":[]},{"title":"Git","level":"1.3.8","depth":2,"path":"notes/git.md","ref":"notes/git.md","articles":[]},{"title":"Power Point","level":"1.3.9","depth":2,"path":"notes/git.md","ref":"notes/git.md","articles":[]},{"title":"PyPlot","level":"1.3.10","depth":2,"path":"notes/pyplot.md","ref":"notes/pyplot.md","articles":[]}]},"previous":{"title":"Deep Compression","level":"1.2.7","depth":2,"path":"Network Quantization/Deep Compression.md","ref":"Network Quantization/Deep Compression.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","splitter","back-to-top-button","etoc","-search","-lunr","search-pro"],"pluginsConfig":{"etoc":{"h2lb":3,"header":1,"maxdepth":4,"mindepth":3,"notoc":false},"splitter":{},"search-pro":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"Network Quantization/Integer Arithmetic Only Inference.md","mtime":"2018-02-01T09:35:37.693Z","type":"markdown"},"gitbook":{"version":"3.2.2","time":"2018-02-01T09:40:03.756Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-etoc/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

